# weibo_crawler_fixed.py
# !/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¿®å¤ç‰ˆå¾®åšçˆ¬è™« - æ”¯æŒè¯„è®ºçˆ¬å–å’Œå…³é”®å­—å…³è”
"""
import traceback
import json
import time
import re
import requests
import pymysql
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from urllib.parse import quote
import logging
import sys
import os
import random

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('weibo_crawler_fixed.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class WeiboCrawlerFixed:
    def __init__(self, config_path='config.json'):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.config = self.load_config(config_path)
        self.session = requests.Session()
        self.setup_session()
        self.db_connection = None

    def load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼š{e}")
            raise

    def setup_session(self):
        """è®¾ç½®è¯·æ±‚ä¼šè¯"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://weibo.com/',
        }

        if 'headers' in self.config:
            headers.update(self.config['headers'])

        self.session.headers.update(headers)

        if self.config.get('proxies'):
            self.session.proxies.update(self.config['proxies'])

    def get_random_delay(self):
        """è·å–éšæœºå»¶è¿Ÿæ—¶é—´"""
        delay_config = self.config['crawler_settings']['request_delay']
        if isinstance(delay_config, (list, tuple)) and len(delay_config) == 2:
            return random.uniform(delay_config[0], delay_config[1])
        return delay_config if delay_config else 2

    def connect_database(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            mysql_config = self.config['mysql_config'].copy()
            mysql_config['charset'] = 'utf8mb4'

            # ç¡®ä¿ç«¯å£æ­£ç¡®
            if 'port' not in mysql_config:
                mysql_config['port'] = 3307  # æ ¹æ®ä½ çš„é…ç½®

            self.db_connection = pymysql.connect(**mysql_config)
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥ï¼š{e}")
            return False

    def safe_get_text(self, element, default=''):
        """å®‰å…¨è·å–æ–‡æœ¬å†…å®¹"""
        try:
            return element.get_text(strip=True) if element else default
        except Exception:
            return default

    def get_keyword_id(self, keyword):
        """è·å–å…³é”®å­—ID"""
        if not self.db_connection:
            return None

        try:
            with self.db_connection.cursor() as cursor:
                cursor.execute("SELECT id FROM keywords WHERE keyword = %s", (keyword,))
                result = cursor.fetchone()
                return result[0] if result else None
        except Exception as e:
            logger.error(f"è·å–å…³é”®å­—IDé”™è¯¯ï¼š{e}")
            return None

    def parse_weibo_item(self, item):
        """è§£æå•ä¸ªå¾®åšæ¡ç›® - æ”¹è¿›ç‰ˆæœ¬"""
        try:
            # è·å–å¾®åšID - å¤šç§æ–¹å¼å°è¯•
            weibo_id = ''

            # æ–¹å¼1: ä»midå±æ€§è·å–
            mid_match = re.search(r'mid="(\d+)"', str(item))
            if mid_match:
                weibo_id = mid_match.group(1)

            # æ–¹å¼2: ä»æ•°æ®æ¨¡å—è·å–
            if not weibo_id:
                module_match = re.search(r'&id=(\d+)', str(item))
                if module_match:
                    weibo_id = module_match.group(1)

            # æ–¹å¼3: ä»é“¾æ¥è·å–
            if not weibo_id:
                link_elem = item.find('a', href=re.compile(r'weibo\.com/\d+/(\w+)'))
                if link_elem:
                    href = link_elem.get('href', '')
                    weibo_match = re.search(r'weibo\.com/\d+/(\w+)', href)
                    if weibo_match:
                        weibo_id = weibo_match.group(1)

            # æ–¹å¼4: ä»è¯„è®ºé“¾æ¥è·å–
            if not weibo_id:
                comment_links = item.find_all('a', href=re.compile(r'comment'))
                for link in comment_links:
                    href = link.get('href', '')
                    id_match = re.search(r'&id=(\d+)', href)
                    if id_match:
                        weibo_id = id_match.group(1)
                        break

            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨æ—¶é—´æˆ³ï¼ˆä½œä¸ºæœ€åæ‰‹æ®µï¼‰
            if not weibo_id:
                weibo_id = str(int(time.time() * 1000))
                logger.warning(f"ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºå¾®åšID: {weibo_id}")

            # è·å–å¾®åšå†…å®¹
            content_elem = item.find('div', class_='content')
            if not content_elem:
                return None

            # è·å–æ­£æ–‡ - å¤šç§é€‰æ‹©å™¨å°è¯•
            text = ''
            text_selectors = [
                'p.txt', 'div.txt', 'p.content', 'div.content'
            ]

            for selector in text_selectors:
                text_elem = content_elem.select_one(selector)
                if text_elem:
                    text = self.safe_get_text(text_elem)
                    if text:
                        break

            # æ¸…ç†æ–‡æœ¬
            if text:
                text = re.sub(r'\s+', ' ', text).strip()

            # è·å–å‘å¸ƒæ—¶é—´
            time_elem = content_elem.find('p', class_='from')
            time_str = ''
            if time_elem:
                time_link = time_elem.find('a')
                time_str = self.safe_get_text(time_link)

            timestamp = self.parse_time_string(time_str) if time_str else int(time.time())

            # è·å–å›¾ç‰‡
            pics = []
            pic_elems = content_elem.find_all('img')
            for img in pic_elems:
                src = img.get('src', '')
                if src and 'sinaimg.cn' in src:
                    # è½¬æ¢ä¸ºé«˜æ¸…å›¾ç‰‡URL
                    if 'orj360' in src:
                        src = src.replace('orj360', 'large')
                    elif 'thumbnail' in src:
                        src = src.replace('thumbnail', 'large')
                    pics.append(src)

            return {
                'id': weibo_id,
                'text': text,
                'pics': ','.join(pics),
                'timestamp': timestamp,
                'source': 'æ–°æµªå¾®åš'
            }

        except Exception as e:
            logger.error(f"è§£æå¾®åšæ¡ç›®é”™è¯¯ï¼š{e}")
            return None

    def parse_time_string(self, time_str):
        """è§£ææ—¶é—´å­—ç¬¦ä¸²"""
        try:
            now = datetime.now()

            if 'åˆ†é’Ÿå‰' in time_str:
                minutes = int(re.search(r'(\d+)', time_str).group(1))
                return int((now - timedelta(minutes=minutes)).timestamp())
            elif 'å°æ—¶å‰' in time_str:
                hours = int(re.search(r'(\d+)', time_str).group(1))
                return int((now - timedelta(hours=hours)).timestamp())
            elif 'ä»Šå¤©' in time_str:
                time_part = re.search(r'ä»Šå¤©\s*(\d+):(\d+)', time_str)
                if time_part:
                    hour, minute = int(time_part.group(1)), int(time_part.group(2))
                    return int(now.replace(hour=hour, minute=minute, second=0).timestamp())
            elif 'æœˆ' in time_str and 'æ—¥' in time_str:
                match = re.search(r'(\d+)æœˆ(\d+)æ—¥', time_str)
                if match:
                    month, day = int(match.group(1)), int(match.group(2))
                    year = now.year
                    return int(datetime(year, month, day).timestamp())

            return int(now.timestamp())

        except Exception as e:
            logger.error(f"æ—¶é—´è§£æé”™è¯¯ï¼š{e}")
            return int(time.time())

    def crawl_weibo_comments(self, weibo_id):
        """çˆ¬å–å•æ¡å¾®åšçš„è¯„è®º - æ”¹è¿›ç‰ˆæœ¬"""
        if not weibo_id or weibo_id == '0' or len(weibo_id) < 10:
            return []

        try:
            # ä½¿ç”¨ä¸åŒçš„è¯„è®ºAPI
            url = "https://weibo.com/ajax/statuses/buildComments"
            params = {
                "is_reload": 1,
                "id": weibo_id,
                "is_show_bulletin": 2,
                "is_mix": 0,
                "count": 10,
                "uid": "",
                "fetch_level": 0
            }

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Referer': f'https://weibo.com/{weibo_id}',
                'X-Requested-With': 'XMLHttpRequest',
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            }

            # ä½¿ç”¨é…ç½®ä¸­çš„Cookie
            if 'headers' in self.config and 'Cookie' in self.config['headers']:
                headers['Cookie'] = self.config['headers']['Cookie']

            logger.info(f"çˆ¬å–è¯„è®º: {weibo_id}")

            # å¢åŠ è¶…æ—¶å’Œé‡è¯•
            for attempt in range(3):
                try:
                    response = self.session.get(url, params=params, headers=headers, timeout=15)

                    if response.status_code == 200:
                        data = response.json()
                        break
                    elif response.status_code == 403:
                        logger.warning(f"è¯„è®ºè¯·æ±‚è¢«æ‹’ç»ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
                        return []
                    else:
                        logger.warning(f"è¯„è®ºè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}ï¼Œå°è¯• {attempt + 1}/3")
                        time.sleep(2)
                except Exception as e:
                    logger.warning(f"è¯„è®ºè¯·æ±‚å¼‚å¸¸ï¼Œå°è¯• {attempt + 1}/3: {e}")
                    time.sleep(2)
            else:
                logger.error("è¯„è®ºè¯·æ±‚å¤šæ¬¡å¤±è´¥")
                return []

            # æ£€æŸ¥å“åº”æ•°æ®
            if not data:
                logger.warning("è¯„è®ºå“åº”æ•°æ®ä¸ºç©º")
                return []

            # ä¸åŒçš„æ•°æ®æ ¼å¼å¤„ç†
            comments = []

            # æ ¼å¼1: ç›´æ¥åŒ…å«dataæ•°ç»„
            if 'data' in data and isinstance(data['data'], list):
                comment_list = data['data']
            # æ ¼å¼2: åµŒå¥—çš„dataç»“æ„
            elif 'data' in data and 'data' in data['data']:
                comment_list = data['data']['data']
            else:
                logger.warning(f"è¯„è®ºæ•°æ®æ ¼å¼æœªçŸ¥: {data.keys() if data else 'ç©ºæ•°æ®'}")
                return []

            for item in comment_list:
                try:
                    comment = {
                        "id": str(item.get("id", "")),
                        "weibo_id": weibo_id,
                        "user": item.get("user", {}).get("screen_name", ""),
                        "content": item.get("text", "") or item.get("text_raw", ""),
                        "timestamp": item.get("created_at", "")
                    }

                    # æ¸…ç†HTMLæ ‡ç­¾
                    if comment["content"]:
                        comment["content"] = re.sub(r'<[^>]+>', '', comment["content"])

                    # è½¬æ¢æ—¶é—´æˆ³
                    try:
                        if comment["timestamp"]:
                            # å°è¯•å¤šç§æ—¶é—´æ ¼å¼
                            try:
                                dt = datetime.strptime(comment["timestamp"], "%a %b %d %H:%M:%S %z %Y")
                            except ValueError:
                                try:
                                    dt = datetime.strptime(comment["timestamp"], "%Y-%m-%d %H:%M:%S")
                                except ValueError:
                                    dt = datetime.now()
                            comment["timestamp"] = int(dt.timestamp())
                        else:
                            comment["timestamp"] = int(time.time())
                    except:
                        comment["timestamp"] = int(time.time())

                    # åªä¿å­˜æœ‰å†…å®¹çš„è¯„è®º
                    if comment["content"].strip():
                        comments.append(comment)

                except Exception as e:
                    logger.warning(f"è§£æè¯„è®ºé¡¹å¤±è´¥: {e}")
                    continue

            logger.info(f"æˆåŠŸè·å– {len(comments)} æ¡è¯„è®º")
            return comments

        except Exception as e:
            logger.error(f"çˆ¬å–è¯„è®ºé”™è¯¯ï¼š{e}")
            return []

    def save_to_database(self, weibo_data, keyword_id):
        """ä¿å­˜å¾®åšæ•°æ®åˆ°æ•°æ®åº“"""
        if not weibo_data or not self.db_connection or not keyword_id:
            return False

        try:
            with self.db_connection.cursor() as cursor:
                sql = """
                INSERT INTO weibo_data (id, keyword_id, text, pics, timestamp, source)
                VALUES (%s, %s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                text = VALUES(text),
                pics = VALUES(pics),
                timestamp = VALUES(timestamp),
                source = VALUES(source),
                updated_at = CURRENT_TIMESTAMP
                """

                cursor.execute(sql, (
                    weibo_data['id'],
                    keyword_id,
                    weibo_data['text'],
                    weibo_data['pics'],
                    weibo_data['timestamp'],
                    weibo_data['source']
                ))

                self.db_connection.commit()
                logger.info(f"ä¿å­˜å¾®åšæˆåŠŸï¼š{weibo_data['id']}")
                return True

        except Exception as e:
            logger.error(f"æ•°æ®åº“ä¿å­˜é”™è¯¯ï¼š{e}")
            if self.db_connection:
                self.db_connection.rollback()
            return False

    def save_comments_to_database(self, comments):
        """ä¿å­˜è¯„è®ºåˆ°æ•°æ®åº“"""
        if not comments or not self.db_connection:
            return 0

        saved_count = 0
        try:
            with self.db_connection.cursor() as cursor:
                sql = """
                INSERT INTO comments (id, weibo_id, user, content, timestamp)
                VALUES (%s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                user = VALUES(user),
                content = VALUES(content),
                timestamp = VALUES(timestamp),
                updated_at = CURRENT_TIMESTAMP
                """

                for comment in comments:
                    try:
                        cursor.execute(sql, (
                            comment['id'],
                            comment['weibo_id'],
                            comment['user'],
                            comment['content'],
                            comment['timestamp']
                        ))
                        saved_count += 1
                    except Exception as e:
                        logger.warning(f"ä¿å­˜è¯„è®º {comment.get('id')} å¤±è´¥ï¼š{e}")
                        continue

                self.db_connection.commit()
                return saved_count

        except Exception as e:
            logger.error(f"è¯„è®ºæ‰¹é‡ä¿å­˜é”™è¯¯ï¼š{e}")
            if self.db_connection:
                self.db_connection.rollback()
            return saved_count

    def crawl_weibo_search(self, keyword, page=1):
        """çˆ¬å–å¾®åšæœç´¢é¡µé¢"""
        try:
            encoded_keyword = quote(keyword.encode('utf-8'))
            url = f"https://s.weibo.com/weibo?q={encoded_keyword}&page={page}"

            logger.info(f"çˆ¬å–URL: {url}")

            response = self.session.get(url, timeout=20)

            if response.status_code != 200:
                logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
                return []

            # ç¼–ç å¤„ç†
            try:
                response.encoding = 'utf-8'
                content = response.text
            except UnicodeDecodeError:
                try:
                    response.encoding = 'gb18030'
                    content = response.text
                except UnicodeDecodeError:
                    content = response.content.decode('utf-8', errors='ignore')

            # æ£€æŸ¥åçˆ¬
            if any(pattern in content for pattern in ['å¼‚å¸¸è¯·æ±‚', 'éªŒè¯ç ', 'security.weibo.com']):
                logger.warning("é‡åˆ°åçˆ¬æœºåˆ¶")
                return []

            # è§£æHTML
            soup = BeautifulSoup(content, 'html.parser')
            weibo_items = []

            # æŸ¥æ‰¾å¾®åšå¡ç‰‡
            selectors = ['div.card', 'div[action-type="feed_list_item"]', 'div.web-feed']

            for selector in selectors:
                card_elems = soup.select(selector)
                if card_elems:
                    for card in card_elems:
                        if card.find('div', class_=re.compile('content')):
                            weibo_data = self.parse_weibo_item(card)
                            if weibo_data and weibo_data['text']:
                                weibo_items.append(weibo_data)
                    break

            logger.info(f"æ‰¾åˆ° {len(weibo_items)} æ¡å¾®åš")
            return weibo_items

        except Exception as e:
            logger.error(f"çˆ¬å–æœç´¢é¡µé¢é”™è¯¯ï¼š{e}")
            return []

    def crawl_keywords(self):
        """çˆ¬å–æ‰€æœ‰å…³é”®è¯"""
        if not self.connect_database():
            return False

        try:
            keywords = self.config['keywords']
            start_page = self.config['startPage']
            max_page = self.config['maxPage']

            # è·å–è¯„è®ºçˆ¬å–é…ç½®å¹¶æ·»åŠ è°ƒè¯•ä¿¡æ¯
            crawl_comments = self.config.get('crawl_comments', False)
            logger.info(f"è¯„è®ºçˆ¬å–é…ç½®: crawl_comments = {crawl_comments}")
            logger.info(f"å®Œæ•´é…ç½®: {self.config.get('crawl_comments', 'æœªæ‰¾åˆ°')}")

            total_saved = 0
            total_comments_saved = 0

            for keyword in keywords:
                logger.info(f"å¼€å§‹çˆ¬å–å…³é”®è¯ï¼š{keyword}")

                # è·å–å…³é”®å­—ID
                keyword_id = self.get_keyword_id(keyword)
                if not keyword_id:
                    logger.error(f"æ— æ³•è·å–å…³é”®å­— '{keyword}' çš„IDï¼Œè·³è¿‡")
                    continue

                for page in range(start_page, max_page + 1):
                    logger.info(f"çˆ¬å–ç¬¬ {page} é¡µ")

                    weibo_items = self.crawl_weibo_search(keyword, page)

                    saved_count = 0
                    for item in weibo_items:
                        if self.save_to_database(item, keyword_id):
                            saved_count += 1

                            # åªæœ‰åœ¨é…ç½®å¼€å¯æ—¶æ‰çˆ¬å–è¯„è®º
                            # åœ¨ crawl_keywords æ–¹æ³•ä¸­ç®€åŒ–è¯„è®ºçˆ¬å–é€»è¾‘
                            if self.config.get('crawl_comments', False):
                                logger.info(f"è¯„è®ºçˆ¬å–å·²å¯ç”¨ï¼Œå¼€å§‹çˆ¬å–å¾®åš {item['id']} çš„è¯„è®º")
                                comments = self.crawl_weibo_comments(item['id'])
                                if comments:
                                    comments_saved = self.save_comments_to_database(comments)
                                    total_comments_saved += comments_saved
                                    logger.info(f"å¾®åš {item['id']} ä¿å­˜äº† {comments_saved} æ¡è¯„è®º")
                                else:
                                    logger.info(f"å¾®åš {item['id']} æ²¡æœ‰è·å–åˆ°è¯„è®º")

                                # è¯„è®ºçˆ¬å–å»¶è¿Ÿ
                                time.sleep(self.get_random_delay() / 2)
                            else:
                                logger.info(f"è·³è¿‡è¯„è®ºçˆ¬å– - crawl_comments: {crawl_comments}, å¾®åšID: {item['id']}")

                    total_saved += saved_count
                    logger.info(f"ç¬¬ {page} é¡µä¿å­˜äº† {saved_count} æ¡å¾®åš")

                    # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œåœæ­¢ç¿»é¡µ
                    if len(weibo_items) == 0:
                        logger.info(f"å…³é”®è¯ {keyword} ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œåœæ­¢çˆ¬å–")
                        break

                    # éšæœºå»¶è¿Ÿ
                    delay = self.get_random_delay()
                    logger.info(f"ç­‰å¾… {delay:.2f} ç§’åç»§ç»­")
                    time.sleep(delay)

                logger.info(f"å…³é”®è¯ {keyword} çˆ¬å–å®Œæˆ")

            logger.info(f"æ‰€æœ‰å…³é”®è¯çˆ¬å–å®Œæˆï¼Œå…±ä¿å­˜ {total_saved} æ¡å¾®åšï¼Œ{total_comments_saved} æ¡è¯„è®º")
            return True

        except Exception as e:
            logger.error(f"çˆ¬å–è¿‡ç¨‹å‡ºé”™ï¼š{e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
        finally:
            if self.db_connection:
                self.db_connection.close()
                logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")


# ä¿®æ”¹ main å‡½æ•°ä¸­çš„æ•°æ®åº“åˆå§‹åŒ–éƒ¨åˆ†
def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¾®åšçˆ¬è™«å¯åŠ¨ä¸­...")
    print("=" * 50)

    try:
        # å…ˆæ£€æŸ¥æ•°æ®åº“è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        try:
            from db_setup2_0 import create_tables, load_config
            config = load_config()
            mysql_config = config['mysql_config']
            keywords = config.get('keywords', [])
            create_tables(mysql_config, keywords)
            print("âœ… æ•°æ®åº“è¡¨æ£€æŸ¥å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“è¡¨æ£€æŸ¥å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ: {e}")

        crawler = WeiboCrawlerFixed()

        if crawler.crawl_keywords():
            print("âœ… çˆ¬å–å®Œæˆï¼")
        else:
            print("âŒ çˆ¬å–å¤±è´¥")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­çˆ¬å–")
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯ï¼š{e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()